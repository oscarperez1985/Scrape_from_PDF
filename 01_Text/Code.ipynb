{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d89f7d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to process one or multiple files (single/multiple): multiple\n",
      "     Processing all files\n",
      "The 'Output' directory is created!\n",
      "The output files were initialized... proceeding to execute the function\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing file 0258-5996_ROB.pdf: 100%|███████████████████████████████████████████████| 79/79 [00:10<00:00,  7.20it/s]\n"
     ]
    }
   ],
   "source": [
    "# SCRIPT TO SCRAPE BAD SHOTS FROM OBSERVER LOGS IN PDF FORMAT\n",
    "\n",
    "# NOTES:\n",
    "# The code assumes a 3 digit format NUMBER for channels and 4 digitS for shots\n",
    "\n",
    "#____________________________________________________________IMPORT LIBRARIES\n",
    "import re\n",
    "import os\n",
    "import PyPDF2\n",
    "import openpyxl\n",
    "from openpyxl import Workbook\n",
    "from time import sleep\n",
    "from tqdm import tqdm\n",
    "\n",
    "#____________________________________________________________INPUT DATA\n",
    "# Location of the PDF files (Observer Logs)\n",
    "pdf_path = r'./Observer_Logs/'\n",
    "\n",
    "# list files inside folder\n",
    "pdf_list = os.listdir(pdf_path)\n",
    "\n",
    "#____________________________________________________________VARIABLES (REQUIRE USER INTERVENTION)\n",
    "rcvmin = 1     #Survey Parameter: Minimum Channel\n",
    "rcvmax = 320   #Survey Parameter: Maximum Channel\n",
    "\n",
    "# Search for turn noise between these patterns \n",
    "pattern1_top = 'Line-segments'\n",
    "pattern1_bot = 'Tape-list'\n",
    "\n",
    "# Search for bad records between these patterns\n",
    "pattern2_top = 'Seismic Data Annotations'\n",
    "pattern2_bot = 'Comment'\n",
    "\n",
    "#____________________________________________________________CHOOSE TO PROCESS ONE OR MULTIPLE FILES\n",
    "def let_user_pick(options):\n",
    "    print(\"     Choose a number to select a file from the list: \")\n",
    "\n",
    "    for idx, element in enumerate(options):\n",
    "        print(\"{}) {}\".format(idx + 1, element))\n",
    "\n",
    "    i = input(\"Entered number: \")\n",
    "    try:\n",
    "        if 0 < int(i) <= len(options):\n",
    "            return int(i) - 1\n",
    "    except:\n",
    "        pass\n",
    "    return None\n",
    "    \n",
    "question = input('Do you want to process one or multiple files (single/multiple): ')\n",
    "\n",
    "if question.lower() == 'single':\n",
    "    response = let_user_pick(pdf_list)\n",
    "    single_file = pdf_path + pdf_list[response]\n",
    "    print(f\"          Processing file {pdf_list[response]}\")\n",
    "elif question.lower() == 'multiple':\n",
    "    print('     Processing all files')\n",
    "else:\n",
    "    print(\"     Please type 'single' or 'multiple... exiting'\")\n",
    "\n",
    "# Single PDF for testing (COMMENT the single_file row if you want to process all files):\n",
    "#one_pdf = '0258-5065_ROB.pdf'\n",
    "#single_file = pdf_path + one_pdf  \n",
    "\n",
    "#____________________________________________________________OUTPUT DATA\n",
    "# Directory to contain the output files.\n",
    "out_dir = \"Output\"\n",
    "\n",
    "# Create if does not exits.\n",
    "isExist = os.path.exists(out_dir)\n",
    "if not isExist:\n",
    "    os.makedirs(out_dir)   \n",
    "\n",
    "print(\"The 'Output' directory is created!\")\n",
    "\n",
    "# Output Excel File\n",
    "xlsx = './' + out_dir + '/Bad_Records.xlsx'\n",
    "wb = Workbook()\n",
    "ws = wb.active\n",
    "ws.title = \"Bad Records\"\n",
    "ws.append(['Line_Number', 'Shot_Min', 'Shot_Max', 'Rcv_Min', 'Rcv_Max', 'Comment'])\n",
    "wb.create_sheet('Turn Lines')\n",
    "ws = wb['Turn Lines']\n",
    "ws.append(['Lines with reported turn noise shots'])\n",
    "wb.save(xlsx)\n",
    "\n",
    "print(\"The output files were initialized... proceeding to execute the function\")\n",
    "\n",
    "#____________________________________________________________EXECUTE THE FUNCTION\n",
    "def scrape_pdf(pdf):\n",
    "    \n",
    "    #____________________________________________________________READ PDFs\n",
    "    # Open the Observer Log PDF file\n",
    "    pdfFileObject = open(pdf, 'rb')\n",
    "    pdfReader = PyPDF2.PdfFileReader(pdfFileObject, strict=False)\n",
    "    numPages = pdfReader.numPages\n",
    "    \n",
    "    #____________________________________________________________INITIALIZE OUTPUT FILE(s)\n",
    "    # Define current acquisition line number\n",
    "    line = re.findall(r\"[-](.+)[_]\",pdf)\n",
    "    line_number = ''.join(line)\n",
    "    \n",
    "    # Define the output file that will be read by TRACE_SELECT in Omega\n",
    "    template_file = \"./\" + out_dir + \"/TRACE_SELECT_line_\" + line_number + \".txt\"    \n",
    "    \n",
    "    header = \"'Key' 'Use Absolute Value of Key' 'First' 'Last' 'Increment' 'Tolerance' 'Operation to Perform' 'Exclude' 'And/Or'\"\n",
    "    template_txt = open(template_file, \"w\")\n",
    "    template_line = template_txt.write(header + '\\n')\n",
    "    template_txt.close()\n",
    "    \n",
    "    #____________________________________________________________NESTED FUNCTIONS TO APPEND TO OUTPUT\n",
    "    global wb\n",
    "    global ws\n",
    "    \n",
    "    def write(file):\n",
    "        text = f\"\"\"'IDENT_NUM' 'NO' {spmin[0]} {spmax[0]} NOT_USED 0 NOT_USED 'NO' 'AND'\n",
    "'TRACE_NUM' 'NO' {rcmin} {rcmax} NOT_USED 0 NOT_USED 'NO' 'OR'\"\"\"\n",
    "        \n",
    "        template_txt = open(file, \"a\")\n",
    "        template_line = template_txt.write(text + '\\n')\n",
    "        template_txt.close()\n",
    "        \n",
    "        ws = wb['Bad Records']\n",
    "        ws.append([line_number, int(spmin[0]), int(spmax[0]), rcmin, rcmax, comment])\n",
    "        wb.save(xlsx)\n",
    "        \n",
    "    def parse_int(inp):\n",
    "        global rcvmax\n",
    "        if inp:\n",
    "            rcv_max = rcvmax + 1\n",
    "            for i in inp:\n",
    "                i_int = int(i)\n",
    "                if i_int in range(rcvmin, rcv_max, 1):\n",
    "                    return i_int\n",
    "        \n",
    "    output = []\n",
    "    \n",
    "    #____________________________________________________________SCRAPE TEXT FROM PDF\n",
    "    for i in range(numPages):\n",
    "        content = pdfReader.getPage(i)\n",
    "        page = content.extractText()\n",
    "        output.append(page)\n",
    "            \n",
    "    # Merge all pages into a single string\n",
    "    text = ''.join(output)\n",
    "    \n",
    "    #____________________________________________________________IDENTIFY TURN LINES\n",
    "    # Extract text to identify if there were shots during vessel turn\n",
    "    turn_text = re.findall(rf\"{pattern1_top}.*?{pattern1_bot}\", text, re.DOTALL)     \n",
    "        \n",
    "    for line in turn_text:\n",
    "        turn = re.findall(r\"[tT]urn|[bB]en[dt]\",line)\n",
    "        if turn:\n",
    "            # Write lines with turn noise\n",
    "            ws = wb['Turn Lines']\n",
    "            ws.append([line_number])\n",
    "            wb.save(xlsx)\n",
    "        \n",
    "    #____________________________________________________________IDENTIFY NOISY RECORDS\n",
    "    # Extract lines between patterns. Bad shot/channels are listed within these patterns\n",
    "    extracted_text = re.findall(rf\"{pattern2_top}.*?{pattern2_bot}\", text, re.DOTALL)\n",
    "        \n",
    "    # Split the text at the break\n",
    "    for i in extracted_text:\n",
    "        text_row = i.split('\\n')\n",
    "            \n",
    "    matched_text_list = []\n",
    "        \n",
    "    # Search for specific noise keywords\n",
    "    for line in text_row:\n",
    "        rematch = re.findall(r\"[tT]urn.*[nN]oise|[bB]en[dt]|[cC]urrent.*[nN]oise|[sS]hip.*[nN]oise|[sS]pik[ey]|[bB]ad.*[sS]hot\",line)\n",
    "        if rematch:\n",
    "            matched_text_list.append(line) \n",
    "\n",
    "    # Regular Expressions to Match Bad Shots and Receivers\n",
    "    mark = 0 \n",
    "    \n",
    "    for line in matched_text_list:\n",
    "        comments = re.sub(r'([^a-zA-Z])', '', line)\n",
    "        comment = comments.replace('ALL', '')\n",
    "        spmin = re.findall(r\"(^\\d{4})[-—–](?:\\d{4})\",line)\n",
    "        spmax = re.findall(r\"(?:^\\d{4})[-—–](\\d{4})\",line)\n",
    "        spsin = re.findall(r\"(^\\d{4})\\s\",line)\n",
    "        rmi = re.findall(r\"(0{0,2}[1-9]|0?[1-9][0-9]|[1-9][0-9][0-9]\\b)[-—–](?:0{0,2}[1-9]|0?[1-9][0-9]|[1-9][0-9][0-9])\\b\",line)\n",
    "        if rmi:\n",
    "            rcmin = parse_int(rmi)\n",
    "        rma = re.findall(r\"(?:0{0,2}[1-9]|0?[1-9][0-9]|[1-9][0-9][0-9]\\b)[-—–](0{0,2}[1-9]|0?[1-9][0-9]|[1-9][0-9][0-9])\\b\",line)\n",
    "        if rma:\n",
    "            rcmax = parse_int(rma)\n",
    "        rcall = re.findall(r\"\\s[aA][lL][lL]\\s\",line)\n",
    "        \n",
    "        if spmin and spmax and rmi and rma:\n",
    "            mark = 1\n",
    "            write(template_file)\n",
    "        elif spmin and spmax and rcall:\n",
    "            mark = 2\n",
    "            rcmin = rcvmin\n",
    "            rcmax = rcvmax\n",
    "            write(template_file)\n",
    "        elif spsin and rcall:\n",
    "            mark = 3\n",
    "            spmin = spsin\n",
    "            spmax = spsin\n",
    "            rcmin = rcvmin\n",
    "            rcmax = rcvmax\n",
    "            write(template_file)\n",
    "        elif spsin and rmi and rma:\n",
    "            mark = 4\n",
    "            spmin = spsin\n",
    "            spmax = spsin\n",
    "            write(template_file)\n",
    "\n",
    "    # Remove empty files (lines without bad records)\n",
    "    if mark == 0:\n",
    "        os.remove(template_file)\n",
    "\n",
    "#____________________________________________________________EXECUTION STAGE\n",
    "try:\n",
    "    single_file\n",
    "    print(f'Single file {pdf_list[response]} successfully processed')\n",
    "except NameError:\n",
    "    pbar = tqdm(pdf_list[:len(pdf_list)])\n",
    "    for i in pbar:\n",
    "        sleep(0.01)\n",
    "        pbar.set_description(f'Processing file {i}')\n",
    "        file = pdf_path + i\n",
    "        scrape_pdf(file)\n",
    "else:\n",
    "    scrape_pdf(single_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69ea1c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
